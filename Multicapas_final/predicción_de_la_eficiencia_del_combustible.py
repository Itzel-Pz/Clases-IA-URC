# -*- coding: utf-8 -*-
"""Predicción de la eficiencia del combustible.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13CIGeUvX6eW-No-B0yoRm3o661eqHouu
"""

!pip install ucimlrepo

from ucimlrepo import fetch_ucirepo
# importo la función fetch_ucirepo, que sirve para descargar datasets del repositorio UCI automáticamente


# fetch dataset
auto_mpg = fetch_ucirepo(id=9)
# aquí descargo el dataset con ID = 9 dentro del repositorio de UCI
# ese ID corresponde al dataset "Auto MPG" (consumo de gasolina de autos)
# y lo guardo en la variable auto_mpg


# data (as pandas dataframes)
X = auto_mpg.data.features
# aquí guardo en X las características del dataset, ya vienen como un DataFrame de pandas

y = auto_mpg.data.targets
# aquí guardo las etiquetas (targets) del dataset, por ejemplo la variable mpg que es el consumo

X.head() #muestro x

y.head() #muestro y

X.info() #La información de x, como los valores nulos y tipo de dato

y.info() #La información de y, como los valores nulos y tipo de dato

import pandas as pd
# importo pandas para manipular tablas y trabajar con DataFrames


df = pd.concat([X, y], axis=1).dropna()
# aquí uno (concateno) las columnas de X y las de y en un solo DataFrame
# axis=1 significa que las pego por columnas (hacia la derecha)
# luego uso .dropna() para eliminar filas que tengan valores faltantes (NaN)
# así me aseguro de trabajar con datos completos y limpios

from sklearn.model_selection import train_test_split
# importo la función train_test_split para poder dividir mis datos en entrenamiento y prueba


# Use the cleaned dataframe 'df' for the train-test split
X_train, X_test, y_train, y_test = train_test_split(
    df.drop('mpg', axis=1),  # Features (all columns except 'mpg')
    df['mpg'],               # Target (the 'mpg' column)
    test_size=0.2,
    random_state=1
)
# aquí separo las variables X y y en 2 conjuntos:
# X_train y y_train → para entrenar el modelo
# X_test y y_test → para evaluar después del entrenamiento
# test_size=0.2 significa que el 20% de los datos serán para prueba y 80% para entrenamiento
# random_state=1 lo uso para que la división sea siempre igual cada vez que corro el código

print(X_train.shape)
print(X_test.shape)

from sklearn.preprocessing import StandardScaler
# importo StandardScaler que sirve para escalar / normalizar los datos numéricos


scaler = StandardScaler()
# creo el objeto escalador que se va a encargar de estandarizar los datos


X_train = scaler.fit_transform(X_train)
# ajusto el escalador usando SOLO los datos de entrenamiento (fit)
# y transformo X_train para que tenga media 0 y desviación estándar 1 (transform)


X_test = scaler.transform(X_test)
# transformo los datos de prueba con el MISMO escalador
# importante: aquí NO hago .fit, porque el modelo no debe conocer estadísticas del test

import tensorflow as tf                        # importo tensorflow, que es la librería que usaré para crear la red neuronal
from tensorflow.keras import Sequential        # traigo el tipo de modelo "Sequential", que me permite ir agregando capas en orden
from tensorflow.keras.layers import Dense      # importo la capa Dense (capa totalmente conectada)

# Defino mi modelo de red neuronal
model = Sequential([
    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),  # primera capa: tiene 64 neuronas y recibe como entrada el número de columnas que tiene mi X_train
    Dense(32, activation='relu'),                                   # segunda capa: 32 neuronas con activación ReLU
    Dense(16, activation='relu'),                                   # tercera capa: 16 neuronas con activación ReLU
    Dense(1)                                                        # capa de salida: solo 1 neurona porque estoy prediciendo un valor continuo (regresión)
])

from tensorflow.keras.optimizers import Adam   # importo el optimizador Adam, que es uno de los más usados para entrenar redes neuronales

# Tasa de aprendizaje deseada
learning_rate = 0.001                          # aquí defino la tasa de aprendizaje: qué tan rápido se ajustan los pesos del modelo
adam_optimizer = Adam(learning_rate=learning_rate)  # creo una instancia del optimizador Adam usando esa tasa de aprendizaje

model.compile(
    optimizer=adam_optimizer,              # aquí le digo al modelo que use el optimizador Adam que configuré antes
    loss='mean_squared_error',             # como este problema es de regresión, uso MSE como función de pérdida
    metrics=['root_mean_squared_error'],   # además quiero ver el RMSE como métrica para evaluar el rendimiento del modelo
)

history = model.fit(
    X_train, y_train,        # entreno el modelo usando mis datos de entrenamiento (entradas y etiquetas reales)
    epochs=5, batch_size=1,  # voy a entrenar por 5 épocas, procesando 1 muestra por lote (batch) a la vez
    validation_data=(X_test, y_test)  # aquí le paso los datos de prueba para que valide su rendimiento en cada época
)

import matplotlib.pyplot as plt   # importo la librería para graficar

# Graficar la función de pérdida
plt.plot(history.history['loss'], label='Pérdida de entrenamiento')   # dibujo la línea de la pérdida durante el entrenamiento
plt.plot(history.history['val_loss'], label='Pérdida de validación')  # dibujo la línea de la pérdida usando los datos de validación
plt.xlabel('Épocas')                                                  # pongo etiqueta al eje X
plt.ylabel('Pérdida')                                                 # pongo etiqueta al eje Y
plt.legend()                                                          # muestro la leyenda para identificar cada línea
plt.title('Función de pérdida durante el entrenamiento')              # título del gráfico
plt.show()                                                            # muestro la gráfica en pantalla

test_loss, test_mae = model.evaluate(X_test, y_test, verbose=1)   # evalúo el modelo usando los datos de prueba y obtengo la pérdida y el error absoluto medio
print(f'Test Mean Absolute Error: {test_mae:.2f}')                # imprimo el MAE de prueba con 2 decimales

predictions = model.predict(X_test)   # hago predicciones del modelo usando los datos de prueba
comparison = pd.DataFrame({'Actual': y_test.values.flatten(), 'Predicted': predictions.flatten()})  # creo un DataFrame para comparar los valores reales vs los predichos
print(comparison.head())  # muestro las primeras 5 filas para ver cómo se comparan

from sklearn.metrics import r2_score, mean_squared_error   # importo métricas para evaluar el modelo

r2 = r2_score(y_test, predictions)      # calculo el coeficiente R^2 para medir qué tan bien el modelo explica la variabilidad real
print(f'R²: {r2}')                      # imprimo el valor de R^2

mse = mean_squared_error(y_test, predictions)   # calculo el error cuadrático medio entre valores reales y predicciones
print(f'MSE: {mse}')                            # imprimo el MSE