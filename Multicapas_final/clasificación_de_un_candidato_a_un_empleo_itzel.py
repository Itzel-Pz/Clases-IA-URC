# -*- coding: utf-8 -*-
"""Clasificaci√≥n de un candidato a un empleo_itzel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PdFlJaeBCTn4V_WKDV4p3zlLUbEITcWz
"""

import numpy as np
import pandas as pd
# importo NumPy para generar datos num√©ricos aleatorios y pandas para manejar el DataFrame


# Generar dataset sint√©tico con diferentes rangos por habilidad
n_muestras = 5000
# aqu√≠ defino que quiero 5000 muestras (filas), o sea, 5000 "personas" o registros que voy a simular


# Habilidades t√©cnicas: 70-100
tec = np.random.randint(70, 101, (n_muestras, 6))
# en esta l√≠nea genero 6 columnas de habilidades t√©cnicas
# cada valor estar√° entre 70 y 100
# (5000 filas x 6 columnas)


# Habilidades matem√°ticas: 60-90
mat = np.random.randint(60, 91, (n_muestras, 6))
# igual que arriba pero ahora son habilidades matem√°ticas
# estas van desde 60 hasta 90


# Habilidades psicol√≥gicas: 50-85
psi = np.random.randint(50, 86, (n_muestras, 6))
# y aqu√≠ genero habilidades psicol√≥gicas
# que van desde 50 hasta 85


# Nombres de columnas
columnas = [
    'python', 'sql', 'visualizacion_datos', 'excel', 'manejo_apis', 'nube',
    'estadistica', 'probabilidad', 'algebra_lineal', 'calculo', 'optimizacion', 'modelado',
    'trabajo_equipo', 'comunicacion', 'creatividad', 'adaptabilidad', 'liderazgo', 'resolucion_problemas'
]
# aqu√≠ defino el nombre para cada columna que va a tener el DataFrame
# las primeras 6 son t√©cnicas, las siguientes 6 matem√°ticas, las √∫ltimas 6 psicol√≥gicas


# Crear DataFrame
df = pd.DataFrame(np.concatenate([tec, mat, psi], axis=1), columns=columnas)
# concateno las 3 matrices (tec, mat, psi) horizontalmente usando axis=1
# esto me da una matriz de 5000 filas x 18 columnas
# y la convierto a DataFrame usando los nombres de columnas que defin√≠ arriba

# Calcular promedio por grupo y promedio total

prom_tecnologicas = df[['python', 'sql', 'visualizacion_datos', 'excel', 'manejo_apis', 'nube']].mean(axis=1)
# aqu√≠ calculo el promedio de las habilidades tecnol√≥gicas para cada fila (cada persona)
# selecciono las 6 columnas tecnol√≥gicas y saco el .mean() por fila (axis=1)

prom_matematicas  = df[['estadistica', 'probabilidad', 'algebra_lineal', 'calculo', 'optimizacion', 'modelado']].mean(axis=1)
# aqu√≠ hago lo mismo pero con las habilidades matem√°ticas
# tambi√©n son 6 columnas y saca el promedio por persona

prom_psicologicas = df[['trabajo_equipo', 'comunicacion', 'creatividad', 'adaptabilidad', 'liderazgo', 'resolucion_problemas']].mean(axis=1)
# y aqu√≠ obtengo el promedio de las habilidades psicol√≥gicas para cada registro

# Promedio total = promedio de los 3 promedios
prom_total = (prom_tecnologicas + prom_matematicas + prom_psicologicas) / 3
# aqu√≠ combino los tres promedios y saco un promedio general por persona

# Etiqueta: 1 = apto si promedio total > 80
y = (prom_total > 75).astype(int)
# aqu√≠ estoy creando la etiqueta (target)
# si el promedio total es mayor que 75 lo marco como 1 (apto)
# si es 75 o menos lo marco como 0 (no apto)
# .astype(int) convierte True/False en 1/0

# one-hot encoding
y = pd.get_dummies(y).values
# convierto y a one-hot encoding para usarlo en redes neuronales
# por ejemplo:
# 0 -> [1,0]
# 1 -> [0,1]

from sklearn.model_selection import train_test_split
# importo la funci√≥n train_test_split para separar mis datos en entrenamiento y prueba

X_train, X_test, y_train, y_test = train_test_split(
    df, y, test_size=0.2, random_state=42
)
# aqu√≠ separo mis datos:
# X son mis caracter√≠sticas (el DataFrame df)
# y son mis etiquetas (aptos / no aptos)
# test_size=0.2 significa que 20% de los datos ser√°n para prueba y 80% para entrenamiento
# random_state=42 lo pongo para que la separaci√≥n sea reproducible (que d√© el mismo resultado cada vez)


# Escalamiento
from sklearn.preprocessing import StandardScaler
# importo el escalador est√°ndar, que normaliza los datos

scaler = StandardScaler()
# creo el objeto escalador

X_train = scaler.fit_transform(X_train)
# ajusto el escalador usando s√≥lo los datos de entrenamiento
# y transformo X_train para que quede normalizado

X_test = scaler.transform(X_test)
# aqu√≠ transformo X_test usando el mismo escalador
# IMPORTANTE: NO se vuelve a hacer fit con X_test, solo transform
# as√≠ evito fugas de informaci√≥n del test hacia el entrenamiento

from tensorflow.keras.models import Sequential
# importo el modelo secuencial de Keras, que me permite construir la red capa por capa

from tensorflow.keras.layers import Dense
# importo la capa Dense (capa densa totalmente conectada), que es el tipo de capa que voy a usar

from tensorflow.keras.optimizers import Adam
# importo el optimizador Adam, que es el que voy a usar para actualizar los pesos durante el entrenamiento


modelo = Sequential([
    Dense(64, input_shape=(X_train.shape[1],), activation='relu'),
    # primera capa oculta con 64 neuronas
    # input_shape = n√∫mero de caracter√≠sticas que tiene cada ejemplo
    # uso activaci√≥n ReLU para permitir no linealidad

    Dense(32, activation='relu'),
    # segunda capa oculta con 32 neuronas, tambi√©n con ReLU

    Dense(16, activation='relu'),
    # tercera capa oculta con 16 neuronas, tambi√©n ReLU

    Dense(2, activation='softmax')
    # capa de salida con 2 neuronas
    # softmax porque tenemos clasificaci√≥n en dos clases (0 y 1) usando one-hot
])


adam = Adam(learning_rate=0.001)
# aqu√≠ creo el optimizador Adam y le paso una tasa de aprendizaje de 0.001


modelo.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])
# compilo el modelo: le digo qu√© optimizador usar
# 'categorical_crossentropy' es la funci√≥n de p√©rdida para clasificaci√≥n multiclase con one-hot
# y quiero medir 'accuracy', o sea, el porcentaje de aciertos

history = modelo.fit(
    X_train, y_train,
    # aqu√≠ le paso los datos de entrenamiento: X_train (caracter√≠sticas) y y_train (etiquetas)

    epochs=50,
    # entrenar√© el modelo durante 50 √©pocas (50 pasadas completas por el dataset)

    batch_size=8,
    # el modelo va a actualizar los pesos cada 8 muestras
    # esto hace el entrenamiento m√°s estable que batch_size=1 y m√°s preciso que batch_size muy grande

    validation_data=(X_test, y_test),
    # le paso los datos de validaci√≥n para que durante el entrenamiento me muestre c√≥mo va
    # no se entrena con estos datos, solo sirven para evaluar el desempe√±o cada √©poca

    verbose=1
    # verbose=1 significa que quiero ver el progreso de cada √©poca en pantalla
)
# al final, lo que me devuelve fit() lo guardo en `history`
# esto contiene la evoluci√≥n de loss y accuracy en entrenamiento y validaci√≥n

import matplotlib.pyplot as plt
# importo matplotlib para poder graficar la evoluci√≥n del entrenamiento


plt.plot(history.history['loss'], label='P√©rdida de entrenamiento')
# grafico la p√©rdida (loss) del conjunto de entrenamiento guardada en history

plt.plot(history.history['val_loss'], label='P√©rdida de validaci√≥n')
# grafico la p√©rdida del conjunto de validaci√≥n para compararla con el entrenamiento


plt.xlabel('√âpocas')
# le pongo nombre al eje X (cada punto es una √©poca)

plt.ylabel('P√©rdida')
# le pongo nombre al eje Y (los valores de la funci√≥n de p√©rdida)

plt.legend()
# activo la leyenda para distinguir las 2 curvas: entrenamiento vs validaci√≥n

plt.title('Evoluci√≥n de la funci√≥n de p√©rdida')
# le doy t√≠tulo a la gr√°fica

plt.show()
# muestro la gr√°fica en pantalla


loss, acc = modelo.evaluate(X_test, y_test)
# aqu√≠ eval√∫o el modelo final usando los datos de prueba (datos que no vio durante el entrenamiento)
# evaluate regresa la p√©rdida y la exactitud (accuracy)

print(f"\nüîπ Loss: {loss:.4f}  |  Accuracy: {acc:.4f}")
# imprimo en pantalla la p√©rdida y la exactitud, con 4 decimales de precisi√≥n

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, recall_score
# importo las funciones para calcular la matriz de confusi√≥n y el recall (sensibilidad)


pred = modelo.predict(X_test)
# hago predicciones con el modelo usando los datos de prueba
# esto devuelve probabilidades para cada clase

y_pred = np.argmax(pred, axis=1)
# aqu√≠ convierto las probabilidades en la clase predicha (0 o 1)
# argmax() me da el √≠ndice de la neurona con mayor probabilidad

y_true = np.argmax(y_test, axis=1)
# convierto las etiquetas reales (que est√°n en one-hot) a clase num√©rica 0 o 1


cm = confusion_matrix(y_true, y_pred)
# calculo la matriz de confusi√≥n comparando clases reales vs predichas

disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No Apto', 'Apto'])
# preparo el objeto para visualizar la matriz, y le doy etiquetas a cada clase

disp.plot(cmap='Blues')
# grafico la matriz de confusi√≥n como una imagen en tonos azules

plt.show()
# muestro la imagen


sensitivity = recall_score(y_true, y_pred, average=None)
# calculo la sensibilidad (recall) para cada clase por separado
# recall = casos positivos correctamente detectados / casos positivos totales

print("\nSensitivity (Recall) por clase:")
# imprimo el encabezado

print(f"No Apto: {sensitivity[0]:.2f}")
# imprimo recall para la clase 0 (No Apto)

print(f"Apto: {sensitivity[1]:.2f}")
# imprimo recall para la clase 1 (Apto)

nuevo_candidato = np.array([[90, 88, 85, 87, 84, 89,   # t√©cnicas
                             82, 86, 85, 83, 87, 80,   # matem√°ticas
                             70, 75, 80, 72, 78, 74]]) # psicol√≥gicas
# aqu√≠ creo un nuevo "alumno / persona" con sus puntajes en cada una de las 18 habilidades
# es un arreglo de 1 fila x 18 columnas, respetando el orden original de columnas


nuevo_candidato_scaled = scaler.transform(nuevo_candidato)
# IMPORTANT√çSIMO: antes de predecir lo escalo usando el mismo scaler
# debe estar en la misma escala que los datos con los que entren√© el modelo


pred_nuevo = modelo.predict(nuevo_candidato_scaled)
# aqu√≠ hago la predicci√≥n con el modelo, esto devuelve probabilidades:
# algo como [0.15, 0.85] ‚Üí significa mayor probabilidad de ser "Apto"


clase_predicha = np.argmax(pred_nuevo)
# convierto las probabilidades a clase (0 o 1)
# si la segunda posici√≥n es mayor, ser√° 1 = "Apto"


print("Evaluaci√≥n de nuevo candidato:")
print(f"Resultado: {'Apto' if clase_predicha == 1 else 'No Apto'}")
# imprimo el resultado final:
# si clase_predicha == 1 ‚Üí muestro "Apto"
# si clase_predicha == 0 ‚Üí "No Apto"