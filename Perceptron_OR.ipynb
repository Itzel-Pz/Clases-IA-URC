{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5TZV4kCablOoi7SX7CcZQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Itzel-Pz/Clases-IA-URC/blob/main/Perceptron_OR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Operación lógica OR"
      ],
      "metadata": {
        "id": "G4hat6EmM88-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vqWDGyaUBeEw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d33c66de-2eff-46ad-9977-deb4da7f8d27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos de la compuerta OR cargados correctamente\n",
            "X (entradas): [[0 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 1]]\n",
            "Y (salidas): [0 1 1 1]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\"\"\"\n",
        "Implementación del Perceptron para la compuerta lógica OR\n",
        "La compuerta OR tiene la siguiente tabla de verdad:\n",
        "Entrada1 | Entrada2 | Salida\n",
        "    0    |    0     |   0\n",
        "    0    |    1     |   1\n",
        "    1    |    0     |   1\n",
        "    1    |    1     |   1\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Definir los datos de entrenamiento para la compuerta OR\n",
        "# X -> entradas (combinaciones de 0 y 1)\n",
        "# Y -> salidas esperadas según la tabla de verdad OR\n",
        "X = np.array([[0, 0],  # Entrada 1: (0,0) debería producir 0\n",
        "              [0, 1],  # Entrada 2: (0,1) debería producir 1\n",
        "              [1, 0],  # Entrada 3: (1,0) debería producir 1\n",
        "              [1, 1]]) # Entrada 4: (1,1) debería producir 1\n",
        "\n",
        "Y = np.array([0, 1, 1, 1])  # Salidas esperadas para cada entrada\n",
        "\n",
        "# Parámetros del perceptrón\n",
        "lr = 0.1       # Tasa de aprendizaje - controla qué tan rápido aprende el modelo\n",
        "epochs = 10    # Número de épocas - cuántas veces revisará todos los datos\n",
        "weights = np.array([0.1, -0.2])  # Pesos iniciales - valores pequeños aleatorios\n",
        "bias = 0.3     # Sesgo inicial - valor inicial para el umbral\n",
        "\n",
        "print(\"Datos de la compuerta OR cargados correctamente\")\n",
        "print(\"X (entradas):\", X)\n",
        "print(\"Y (salidas):\", Y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "Declaramos nuestra clase Perceptron, que tendrá los siguientes atributos:\n",
        "lr -> tasa de aprendizaje\n",
        "epochs -> numero de epocas\n",
        "weights -> vector de pesos iniciales\n",
        "bias -> sesgo inicial\n",
        "\n",
        "Estos parametros serviran para entrenar el modelo.\n",
        "\"\"\"\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, lr, epochs, weights, bias):\n",
        "        \"\"\"\n",
        "            Constructor del perceptron:\n",
        "            Guarda las variables\n",
        "            lr -> tasa de aprendizaje\n",
        "            epochs -> numero de epocas\n",
        "            weights -> vector de pesos iniciales\n",
        "            bias -> sesgo inicial\n",
        "        \"\"\"\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.weights = weights\n",
        "        self.bias = bias\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        \"\"\"\n",
        "            Realiza el entrenamiento del Perceptron.\n",
        "\n",
        "            declaramos la función fit cuyos parametros son:\n",
        "            X -> entradas\n",
        "            Y -> salidas\n",
        "            Estos parametros se usan para entrenar el modelo.\n",
        "        \"\"\"\n",
        "        # Recorre el dataset la cantidad indicada en epocas\n",
        "        for epoch in range(self.epochs):  # Para cada elemento en un rango que va de 0 a las epocas declaradas hará lo siguiente:\n",
        "            total_error = 0  # Para trackear el error en cada época\n",
        "            for j in range(X.shape[0]):  # Para cada elemento en un elemento que va de 0 al número de filas en el array X hará lo siguiente:\n",
        "                # Calcula la salida del perceptrón para la entrada actual\n",
        "                y_pred = self.activation_function(np.dot(self.weights, X[j]) + self.bias) # Almacenamos en la variable y_pred la evaluación de los datos,\n",
        "                                                                                          # donde se calcula el producto punto con los pesos para cada fila de la\n",
        "                                                                                          # matriz de entrada más el sesgo.\n",
        "\n",
        "                # Calcula el error\n",
        "                loss = Y[j] - y_pred # Calculamos el error, restandole el valor de cada fila (el valor real) menos la variable que contiene la evaluación de los datos (el valor predicho)\n",
        "                total_error += abs(loss)  # Sumamos el error absoluto\n",
        "\n",
        "                # Actualiza los pesos y el sesgo\n",
        "                self.weights += self.lr * loss * X[j]  # Los pesos se actualizan sumando la tasa de aprendizaje multiplicada por el error, multiplicada por los valores de entrada de la fila actual\n",
        "                self.bias += self.lr * loss # El sesgo se actualiza sumando la taza de aprendizaje por el error\n",
        "            print(f\"Epoch {epoch}, Error: {total_error}, Weights: {self.weights}, Bias: {self.bias}\")\n",
        "\n",
        "        # Imprime los valores finales de los parámetros aprendidos\n",
        "        print(f\"Optimized Weights are {self.weights} and bias is {self.bias}\")\n",
        "\n",
        "    #Definición de la función \"activation_function\" donde 'activation' es un PARÁMETRO\n",
        "    def activation_function(self, activation):\n",
        "        \"\"\"\n",
        "            Función de activación escalón\n",
        "        \"\"\"\n",
        "        return 1 if activation >= 0 else 0  # Si la activación es mayor o igual a cero entonces devuelve un 1 sino 0.\n",
        "\n",
        "    def prediction(self, X): # Función predicción que pedirá como parametro cada elemento de X\n",
        "        \"\"\"\n",
        "            Calcula la salida del Perceptron para cada fila de entradas X.\n",
        "        \"\"\"\n",
        "        # Calcula producto punto + bias para todas las entradas\n",
        "        sum_ = np.dot(X, self.weights) + self.bias # Se calcula las predicciones para TODAS las entradas a la vez (vectorización):\n",
        "\n",
        "        # Mensaje input y su predicción\n",
        "        print(\"\\n--- PREDICCIONES COMPUERTA OR ---\")\n",
        "        for i, s in enumerate(sum_):\n",
        "            print(f\"Input: {X[i]} -> Prediction: {self.activation_function(s)} (Esperado: {Y[i]})\")\n",
        "\n",
        "        # Devuelve un array con todas las predicciones\n",
        "        return np.array([self.activation_function(s) for s in sum_])\n",
        "\n",
        "# Crear una instancia del perceptrón\n",
        "p = Perceptron(lr=lr, epochs=epochs, weights=weights, bias=bias) # Mandamos a llamar a la clase, cuyos argumentos declaramos arriba, pero ahora los ingresamos como\n",
        "                                                                # los argumentos de la clase Perceptron\n",
        "\n",
        "print(\" ENTRENAMIENTO DEL PERCEPTRON PARA COMPUERTA OR \")\n",
        "# Entrenar el modelo\n",
        "p.fit(X, Y)"
      ],
      "metadata": {
        "id": "mJqVnmKUVYgC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac21eb3-fcd5-464c-af9a-8bc680e78ddb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ENTRENAMIENTO DEL PERCEPTRON PARA COMPUERTA OR \n",
            "Epoch 0, Error: 1, Weights: [0.1 0.1], Bias: 0.19999999999999998\n",
            "Epoch 1, Error: 1, Weights: [0.1 0.1], Bias: 0.09999999999999998\n",
            "Epoch 2, Error: 1, Weights: [0.1 0.1], Bias: -2.7755575615628914e-17\n",
            "Epoch 3, Error: 0, Weights: [0.1 0.1], Bias: -2.7755575615628914e-17\n",
            "Epoch 4, Error: 0, Weights: [0.1 0.1], Bias: -2.7755575615628914e-17\n",
            "Epoch 5, Error: 0, Weights: [0.1 0.1], Bias: -2.7755575615628914e-17\n",
            "Epoch 6, Error: 0, Weights: [0.1 0.1], Bias: -2.7755575615628914e-17\n",
            "Epoch 7, Error: 0, Weights: [0.1 0.1], Bias: -2.7755575615628914e-17\n",
            "Epoch 8, Error: 0, Weights: [0.1 0.1], Bias: -2.7755575615628914e-17\n",
            "Epoch 9, Error: 0, Weights: [0.1 0.1], Bias: -2.7755575615628914e-17\n",
            "Optimized Weights are [0.1 0.1] and bias is -2.7755575615628914e-17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n EVALUACIÓN DEL MODELO ENTRENADO\")\n",
        "# Usando el modelo entrenado para realizar predicciones\n",
        "predictions = p.prediction(X)\n",
        "\n",
        "# Verificarmdp si aprendió correctamente\n",
        "if np.array_equal(predictions, Y):\n",
        "    print(\"\\nEl perceptrón aprendió correctamente la compuerta OR\")\n",
        "else:\n",
        "    print(\"\\nEl perceptrón no aprendió correctamente\")\n",
        "\n",
        "print(\"\\nResumen final:\")\n",
        "print(\"Pesos finales:\", p.weights)\n",
        "print(\"Sesgo final:\", p.bias)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7uQO0jgVelX",
        "outputId": "1bee5314-864d-4f03-972e-ebd551947517"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " EVALUACIÓN DEL MODELO ENTRENADO\n",
            "\n",
            "--- PREDICCIONES COMPUERTA OR ---\n",
            "Input: [0 0] -> Prediction: 0 (Esperado: 0)\n",
            "Input: [0 1] -> Prediction: 1 (Esperado: 1)\n",
            "Input: [1 0] -> Prediction: 1 (Esperado: 1)\n",
            "Input: [1 1] -> Prediction: 1 (Esperado: 1)\n",
            "\n",
            "El perceptrón aprendió correctamente la compuerta OR\n",
            "\n",
            "Resumen final:\n",
            "Pesos finales: [0.1 0.1]\n",
            "Sesgo final: -2.7755575615628914e-17\n"
          ]
        }
      ]
    }
  ]
}